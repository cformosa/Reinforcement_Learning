{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/reinforcement-learning-w-keras-openai-dqns-1eed3a5338c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a description of the data and space https://github.com/openai/gym/wiki/MountainCar-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    #this sets up the bolltmann parameters\n",
    "    def __init__(self, env):\n",
    "        self.env     = env\n",
    "        self.memory  = deque(maxlen=2000)\n",
    "        \n",
    "        self.gamma = 0.85\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.005\n",
    "        self.tau = .125\n",
    "\n",
    "        self.model        = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    #This creates our model\n",
    "    def create_model(self):\n",
    "        model   = Sequential()\n",
    "        state_shape  = self.env.observation_space.shape\n",
    "        model.add(Dense(24, input_dim=state_shape[0], activation=\"relu\"))\n",
    "        model.add(Dense(48, activation=\"relu\"))\n",
    "        model.add(Dense(24, activation=\"relu\"))\n",
    "        model.add(Dense(self.env.action_space.n))\n",
    "        model.compile(loss=\"mean_squared_error\",\n",
    "            optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    #This is the exploration vs exploitation part. sample() gives us our 1 of 3 action choices. Actually take the action\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return self.env.action_space.sample()\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    #puts the current trial in memory so we can sample from it later and use it\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "    #sample our paths from memory and fit them to get current and future state rewards\n",
    "    def replay(self):\n",
    "        batch_size = 32\n",
    "        if len(self.memory) < batch_size: #don't let it sample from a spot where we don't have at least 32 options\n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size) #samples 32 observations from memory\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = self.target_model.predict(state) #predicts all 3 options in an array\n",
    "            if done:\n",
    "                target[0][action] = reward #if we win/end then there are no more terminal states so we quit\n",
    "            else:\n",
    "                #otherwise choose the the max Q for estimating future reward\n",
    "                Q_future = max(self.target_model.predict(new_state)[0]) \n",
    "                target[0][action] = reward + Q_future * self.gamma #Boltzmann Equation\n",
    "            self.model.fit(state, target, epochs=1, verbose=1)\n",
    "     \n",
    "    #updates the training weights\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            #update training weights as explained in the blog for convergence\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    #saves the weights\n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46930122,  0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "[[-0.50493326  0.00199986]] [[-0.9737966  -0.03538012 -0.08355838]]\n",
      "[[-0.51461785  0.00239345]] [[ 0.03141573 -0.03601095 -0.97349936]]\n",
      "[[-0.54816503  0.        ]] [[ 0.03355893 -0.03870121 -0.9715741 ]]\n",
      "[[-5.04359734e-01 -2.86415473e-04]] [[-0.97363454 -0.03564698 -0.08361523]]\n",
      "[[-5.46475279e-01  4.29488524e-05]] [[ 0.03345388 -0.9715808  -0.09057386]]\n",
      "[[-0.50579036 -0.00143063]] [[-0.97344965 -0.03590182 -0.08392838]]\n",
      "[[-0.53851507  0.00216528]] [[ 0.03288725 -0.9721679  -0.08911347]]\n",
      "[[-0.54698095  0.00118408]] [[-0.9715666  -0.03845843 -0.09058188]]\n",
      "[[-0.50693312  0.0021248 ]] [[ 0.0309553  -0.9737881  -0.08388155]]\n",
      "[[-0.54560398  0.0007215 ]] [[ 0.03337518 -0.03842339 -0.97176623]]\n",
      "[[-0.52593963  0.00348507]] [[-0.9728412  -0.03666353 -0.08694144]]\n",
      "[[-0.50407332  0.00085994]] [[-0.97374535 -0.03547265 -0.08349159]]\n",
      "[[-5.46260891e-01  2.14387976e-04]] [[ 0.03343436 -0.9716062  -0.09052696]]\n",
      "[[-5.45876668e-01  3.84222940e-04]] [[-0.97155637 -0.03848799 -0.09045199]]\n",
      "[[-0.52093559  0.00250141]] [[ 0.03179846 -0.9730998  -0.08617739]]\n",
      "[[-5.46389417e-01 -2.99608291e-04]] [[ 0.03346143 -0.9715565  -0.0905824 ]]\n",
      "[[-0.5170113   0.00144286]] [[ 0.03159777 -0.03630773 -0.97329664]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-0.9715578  -0.03848319 -0.0904775 ]]\n",
      "[[-0.51003291 -0.00167842]] [[ 0.03128719 -0.97331005 -0.08464802]]\n",
      "[[-0.52343701  0.00250263]] [[ 0.03195156 -0.9729713  -0.08659193]]\n",
      "[[-0.50905792  0.00223382]] [[ 0.03108131 -0.973688   -0.0842265 ]]\n",
      "[[-0.53286608  0.00337188]] [[ 0.03249633 -0.9725594  -0.08809701]]\n",
      "[[-5.46621645e-01  3.59302659e-04]] [[ 0.03345102 -0.97159976 -0.09057711]]\n",
      "[[-0.51845415  0.00248144]] [[-0.9731419  -0.03626996 -0.08576744]]\n",
      "[[-5.46325486e-01 -4.48817223e-04]] [[ 0.03346309 -0.03863167 -0.9716311 ]]\n",
      "[[-0.53623796  0.00227711]] [[ 0.03274366 -0.03755301 -0.97237813]]\n",
      "[[-0.54068034  0.00303722]] [[-0.97204584 -0.03776446 -0.08941445]]\n",
      "[[-0.54371756  0.00188642]] [[ 0.03321617 -0.0381336  -0.97196084]]\n",
      "[[-0.50835449 -0.00256413]] [[ 0.0312357  -0.03620329 -0.9734059 ]]\n",
      "[[-5.46518228e-01 -1.28811628e-04]] [[ 0.03346293 -0.97156423 -0.09059239]]\n",
      "[[-0.5294247   0.00344138]] [[ 0.03228305 -0.97274214 -0.087522  ]]\n",
      "[[-0.51129174  0.0033261 ]] [[-0.9735809  -0.03565075 -0.08452418]]\n",
      "[[-5.46621645e-01  3.59302659e-04]] [[ 9.4727613e-05 -9.9993169e-01 -1.2673984e-01]]\n",
      "[[-0.50693312  0.0021248 ]] [[-0.00143898 -1.0012964  -0.11883604]]\n",
      "[[-0.54560398  0.0007215 ]] [[ 6.8637542e-05 -7.5559206e-02 -9.9996525e-01]]\n",
      "[[-0.54371756  0.00188642]] [[ 4.0889252e-05 -7.5201213e-02 -1.0000290e+00]]\n",
      "[[-0.54698095  0.00118408]] [[-0.9999195  -0.07561611 -0.1267768 ]]\n",
      "[[-5.45876668e-01  3.84222940e-04]] [[-0.99995834 -0.07563724 -0.12659182]]\n",
      "[[-0.50835449 -0.00256413]] [[-0.00157724 -0.07258336 -1.0012515 ]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-0.9999509  -0.07563423 -0.1266278 ]]\n",
      "[[-0.50407332  0.00085994]] [[-1.0013974  -0.07164942 -0.11832377]]\n",
      "[[-0.54068034  0.00303722]] [[-1.0001345  -0.07473769 -0.12545742]]\n",
      "[[-0.51181305 -0.00178014]] [[-0.00140441 -0.07278509 -1.0011315 ]]\n",
      "[[-0.51129174  0.0033261 ]] [[-1.0011461  -0.07194126 -0.11964666]]\n",
      "[[-5.46325486e-01 -4.48817223e-04]] [[ 4.8981048e-05 -7.5808972e-02 -9.9994165e-01]]\n",
      "[[-0.51003291 -0.00167842]] [[-0.00147227 -1.0011938  -0.11960407]]\n",
      "[[-0.52593963  0.00348507]] [[-1.0006416  -0.0732879  -0.12253039]]\n",
      "[[-0.53623796  0.00227711]] [[-2.4572713e-04 -7.4440137e-02 -1.0002861e+00]]\n",
      "[[-0.5294247   0.00344138]] [[-4.7305087e-04 -1.0005205e+00 -1.2321987e-01]]\n",
      "[[-0.53851507  0.00216528]] [[-1.5817722e-04 -1.0002089e+00 -1.2506603e-01]]\n",
      "[[-0.5170113   0.00144286]] [[-0.00105928 -0.07276996 -1.000949  ]]\n",
      "[[-5.46475279e-01  4.29488524e-05]] [[ 7.5587071e-05 -9.9993706e-01 -1.2672397e-01]]\n",
      "[[-0.50579036 -0.00143063]] [[-1.0013406  -0.0721668  -0.11875676]]\n",
      "[[-0.53286608  0.00337188]] [[-3.3657439e-04 -1.0004021e+00 -1.2390173e-01]]\n",
      "[[-5.04359734e-01 -2.86415473e-04]] [[-1.0013887  -0.07185472 -0.1184274 ]]\n",
      "[[-0.52343701  0.00250263]] [[-7.5476756e-04 -1.0007278e+00 -1.2207700e-01]]\n",
      "[[-0.50493326  0.00199986]] [[-1.0013665  -0.07155245 -0.11844656]]\n",
      "[[-0.51461785  0.00239345]] [[-0.00111652 -0.07239787 -1.0010304 ]]\n",
      "[[-5.46518228e-01 -1.28811628e-04]] [[ 7.0149545e-05 -9.9993575e-01 -1.2673950e-01]]\n",
      "[[-5.46389417e-01 -2.99608291e-04]] [[ 5.7799742e-05 -9.9994040e-01 -1.2672111e-01]]\n",
      "[[-0.54816503  0.        ]] [[ 1.4222693e-04 -7.5911298e-02 -9.9987781e-01]]\n",
      "[[-0.51845415  0.00248144]] [[-1.0009004  -0.07274333 -0.12109465]]\n",
      "[[-5.46260891e-01  2.14387976e-04]] [[ 7.4063428e-05 -9.9994427e-01 -1.2667462e-01]]\n",
      "[[-0.50905792  0.00223382]] [[-0.00134836 -1.0012231  -0.11925083]]\n",
      "[[-0.5294247   0.00344138]] [[-0.05020846 -1.0426923  -0.15358472]]\n",
      "[[-5.46325486e-01 -4.48817223e-04]] [[-0.05021651 -0.12407512 -1.0426668 ]]\n",
      "[[-5.46260891e-01  2.14387976e-04]] [[-0.05020297 -1.0426712  -0.15769866]]\n",
      "[[-0.54698095  0.00118408]] [[-1.0426688  -0.12401891 -0.1578251 ]]\n",
      "[[-0.52593963  0.00348507]] [[-1.0427221  -0.12098467 -0.1527659 ]]\n",
      "[[-0.54371756  0.00188642]] [[-0.05017869 -0.12351415 -1.0426354 ]]\n",
      "[[-0.50579036 -0.00143063]] [[-1.0428622  -0.11873753 -0.14824797]]\n",
      "[[-5.04359734e-01 -2.86415473e-04]] [[-1.0428535  -0.1184415  -0.14786053]]\n",
      "[[-0.51845415  0.00248144]] [[-1.0427638  -0.12007788 -0.15105443]]\n",
      "[[-5.46518228e-01 -1.28811628e-04]] [[-0.05020875 -1.0426745  -0.1577698 ]]\n",
      "[[-0.50493326  0.00199986]] [[-1.0428226  -0.11830992 -0.147894  ]]\n",
      "[[-0.54560398  0.0007215 ]] [[-0.05019619 -0.12387656 -1.0426519 ]]\n",
      "[[-5.46621645e-01  3.59302659e-04]] [[-0.05019857 -1.042668   -0.15777713]]\n",
      "[[-0.51268156 -0.00086851]] [[-0.05037419 -1.0428158  -0.1498447 ]]\n",
      "[[-5.46475279e-01  4.29488524e-05]] [[-0.0502053  -1.0426725  -0.15775673]]\n",
      "[[-0.52093559  0.00250141]] [[-0.05027252 -1.0427414  -0.15163751]]\n",
      "[[-0.54816503  0.        ]] [[-0.05019977 -0.12428014 -1.0426539 ]]\n",
      "[[-0.50835449 -0.00256413]] [[-0.05042614 -0.11918447 -1.0428413 ]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-1.0426811  -0.12395896 -0.15764433]]\n",
      "[[-0.52343701  0.00250263]] [[-0.0502613 -1.0427316 -0.1522261]]\n",
      "[[-0.50693312  0.0021248 ]] [[-0.05034249 -1.0428008  -0.14835906]]\n",
      "[[-0.54068034  0.00303722]] [[-1.0426687  -0.12299185 -0.15624434]]\n",
      "[[-0.51181305 -0.00178014]] [[-0.05039559 -0.11957647 -1.0428181 ]]\n",
      "[[-0.53623796  0.00227711]] [[-0.05020748 -0.12247889 -1.042663  ]]\n",
      "[[-0.50407332  0.00085994]] [[-1.0428402  -0.1182986  -0.14774226]]\n",
      "[[-0.5170113   0.00144286]] [[-0.05031043 -0.11997922 -1.0427575 ]]\n",
      "[[-0.51003291 -0.00167842]] [[-0.05040162 -1.0428363  -0.14925736]]\n",
      "[[-0.53851507  0.00216528]] [[-0.0501985  -1.0426763  -0.15578742]]\n",
      "[[-0.53286608  0.00337188]] [[-0.05019176 -1.0426772  -0.15439479]]\n",
      "[[-5.46389417e-01 -2.99608291e-04]] [[-0.050213   -1.0426774  -0.15774204]]\n",
      "[[-0.51129174  0.0033261 ]] [[-1.0427812  -0.11904109 -0.14933145]]\n",
      "[[-5.45876668e-01  3.84222940e-04]] [[-1.0426841  -0.12394386 -0.1576007 ]]\n",
      "[[-0.51845415  0.00248144]] [[-1.077469   -0.16815038 -0.17169169]]\n",
      "[[-5.46260891e-01  2.14387976e-04]] [[-0.09246513 -1.0785773  -0.17912003]]\n",
      "[[-5.46325486e-01 -4.48817223e-04]] [[-0.09248441 -0.17361827 -1.07856   ]]\n",
      "[[-5.46518228e-01 -1.28811628e-04]] [[-0.09248502 -1.0786071  -0.17921345]]\n",
      "[[-0.51129174  0.0033261 ]] [[-1.0771531  -0.16673353 -0.16975835]]\n",
      "[[-0.53623796  0.00227711]] [[-0.09197036 -0.17142656 -1.0780249 ]]\n",
      "[[-0.52343701  0.00250263]] [[-0.09139817 -1.0775944  -0.1729901 ]]\n",
      "[[-0.54560398  0.0007215 ]] [[-0.09242348 -0.17333694 -1.0784645 ]]\n",
      "[[-5.46389417e-01 -2.99608291e-04]] [[-0.09248354 -1.0786122  -0.17919292]]\n",
      "[[-5.45876668e-01  3.84222940e-04]] [[-1.0786117  -0.17342985 -0.1790068 ]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-1.078611   -0.17344995 -0.17905115]]\n",
      "[[-0.50693312  0.0021248 ]] [[-0.09067702 -1.0770029  -0.16871302]]\n",
      "[[-0.54698095  0.00118408]] [[-1.0786059  -0.17352952 -0.17923376]]\n",
      "[[-0.54068034  0.00303722]] [[-1.0782628  -0.17214134 -0.17744814]]\n",
      "[[-0.50835449 -0.00256413]] [[-0.09085613 -0.16694914 -1.0772722 ]]\n",
      "[[-0.54816503  0.        ]] [[-0.09255472 -0.17389715 -1.0786021 ]]\n",
      "[[-5.46475279e-01  4.29488524e-05]] [[-0.09247887 -1.0785954  -0.17918909]]\n",
      "[[-0.51363193 -0.00095038]] [[-0.09104973 -0.16770744 -1.0773737 ]]\n",
      "[[-0.52593963  0.00348507]] [[-1.0776885  -0.1693902  -0.17356794]]\n",
      "[[-0.53286608  0.00337188]] [[-0.09179399 -1.077894   -0.17538373]]\n",
      "[[-0.50579036 -0.00143063]] [[-1.0772277  -0.16633573 -0.16868678]]\n",
      "[[-0.54371756  0.00188642]] [[-0.09231112 -0.17284338 -1.078326  ]]\n",
      "[[-0.51003291 -0.00167842]] [[-0.09090848 -1.0773413  -0.16981263]]\n",
      "[[-0.51181305 -0.00178014]] [[-0.09098979 -0.16748103 -1.0773548 ]]\n",
      "[[-0.50493326  0.00199986]] [[-1.0769945  -0.16574089 -0.1682008 ]]\n",
      "[[-0.51461785  0.00239345]] [[-0.09101051 -0.1674605  -1.0772141 ]]\n",
      "[[-0.50407332  0.00085994]] [[-1.0770295  -0.16572936 -0.16806361]]\n",
      "[[-0.50905792  0.00223382]] [[-0.09076837 -1.0770755  -0.16925907]]\n",
      "[[-0.5170113   0.00144286]] [[-0.09114002 -0.16801937 -1.077359  ]]\n",
      "[[-0.52093559  0.00250141]] [[-0.09128749 -1.0775014  -0.1723376 ]]\n",
      "[[-0.53851507  0.00216528]] [[-0.09207394 -1.0781748  -0.17694989]]\n",
      "[[-5.04359734e-01 -2.86415473e-04]] [[-1.0771073  -0.16592811 -0.16822597]]\n",
      "[[-0.51845415  0.00248144]] [[-1.1112072  -0.20357326 -0.19650884]]\n",
      "[[-0.53851507  0.00216528]] [[-0.13247593 -1.1124465  -0.20227787]]\n",
      "[[-0.52343701  0.00250263]] [[-0.13128951 -1.1114315  -0.19793528]]\n",
      "[[-0.51181305 -0.00178014]] [[-0.13055134 -0.20272145 -1.1109965 ]]\n",
      "[[-0.54068034  0.00303722]] [[-1.1126045  -0.20825514 -0.20281479]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-1.1132151  -0.2097485  -0.20456776]]\n",
      "[[-0.51003291 -0.00167842]] [[-0.13040963 -1.1109686  -0.19445194]]\n",
      "[[-0.52593963  0.00348507]] [[-1.1115961  -0.20503998 -0.19856831]]\n",
      "[[-5.46389417e-01 -2.99608291e-04]] [[-0.13319418 -1.1132185  -0.20472567]]\n",
      "[[-0.54371756  0.00188642]] [[-0.13290149 -0.2090596  -1.1127247 ]]\n",
      "[[-0.5294247   0.00344138]] [[-0.13171771 -1.1117293  -0.19957098]]\n",
      "[[-0.53623796  0.00227711]] [[-0.13229004 -0.2074032  -1.1121888 ]]\n",
      "[[-0.53286608  0.00337188]] [[-0.13198683 -1.11196    -0.20056334]]\n",
      "[[-5.13657046e-01 -2.51152316e-05]] [[-1.1111405  -0.20288175 -0.1953489 ]]\n",
      "[[-0.51461785  0.00239345]] [[-0.1306107  -0.20276472 -1.1107702 ]]\n",
      "[[-0.5170113   0.00144286]] [[-0.13083199 -0.20340323 -1.1110191 ]]\n",
      "[[-0.50693312  0.0021248 ]] [[-0.13002577 -1.1103942  -0.19323722]]\n",
      "[[-0.51363193 -0.00095038]] [[-0.1306608  -0.20299974 -1.1110336 ]]\n",
      "[[-0.50905792  0.00223382]] [[-0.1301862  -1.1105219  -0.19383688]]\n",
      "[[-5.46325486e-01 -4.48817223e-04]] [[-0.13319448 -0.20992935 -1.1131302 ]]\n",
      "[[-5.46518228e-01 -1.28811628e-04]] [[-0.13319826 -1.1132103  -0.20474719]]\n",
      "[[-5.45876668e-01  3.84222940e-04]] [[-1.1132153  -0.20972237 -0.20452033]]\n",
      "[[-0.50493326  0.00199986]] [[-1.1103743  -0.20074648 -0.19267471]]\n",
      "[[-0.50407332  0.00085994]] [[-1.11043    -0.2007146  -0.19252601]]\n",
      "[[-5.46621645e-01  3.59302659e-04]] [[-0.13318878 -1.1131691  -0.20473357]]\n",
      "[[-0.54698095  0.00118408]] [[-1.1132104  -0.209853   -0.20476295]]\n",
      "[[-5.04359734e-01 -2.86415473e-04]] [[-1.110561   -0.20092867 -0.19270645]]\n",
      "[[-0.50835449 -0.00256413]] [[-0.13031317 -0.20208651 -1.1108482 ]]\n",
      "[[-0.51268156 -0.00086851]] [[-0.13058412 -1.1110617  -0.19514164]]\n",
      "[[-0.51129174  0.0033261 ]] [[-1.1106583  -0.2019292  -0.19438343]]\n",
      "[[-5.46475279e-01  4.29488524e-05]] [[-0.13318858 -1.1131904  -0.20471989]]\n",
      "[[-0.52093559  0.00250141]] [[-0.13109586 -1.1112688  -0.19721839]]\n",
      "[[-0.5294247   0.00344138]] [[-0.1685627  -1.1429263  -0.21760018]]\n",
      "[[-0.54698095  0.00118408]] [[-1.1450995  -0.24729072 -0.22268297]]\n",
      "[[-0.52093559  0.00250141]] [[-0.16759023 -1.1422026  -0.21535817]]\n",
      "[[-0.50407332  0.00085994]] [[-1.1408657  -0.2365276  -0.21088076]]\n",
      "[[-0.51268156 -0.00086851]] [[-0.16672969 -1.1418183  -0.21343897]]\n",
      "[[-0.51475671 -0.00109967]] [[-0.16698337 -0.23945509 -1.1419251 ]]\n",
      "[[-0.51181305 -0.00178014]] [[-0.16665842 -0.23879658 -1.1417203 ]]\n",
      "[[-5.46260891e-01  2.14387976e-04]] [[-0.17066756 -1.1450238  -0.2225873 ]]\n",
      "[[-0.50579036 -0.00143063]] [[-1.1413347  -0.23723786 -0.21159762]]\n",
      "[[-5.13657046e-01 -2.51152316e-05]] [[-1.1419358  -0.23904783 -0.21361855]]\n",
      "[[-0.53623796  0.00227711]] [[-0.16940959 -0.24445339 -1.1436267 ]]\n",
      "[[-0.5170113   0.00144286]] [[-0.16716227 -0.2397141  -1.1418191 ]]\n",
      "[[-5.46621645e-01  3.59302659e-04]] [[-0.17070526 -1.1450409  -0.2226714 ]]\n",
      "[[-0.50693312  0.0021248 ]] [[-0.16594553 -1.1408561  -0.21153535]]\n",
      "[[-0.51363193 -0.00095038]] [[-0.16684502 -0.23915379 -1.1417936 ]]\n",
      "[[-0.54560398  0.0007215 ]] [[-0.17057224 -0.24700017 -1.1447623 ]]\n",
      "[[-0.51845415  0.00248144]] [[-1.1420879  -0.2399513  -0.21467571]]\n",
      "[[-0.53286608  0.00337188]] [[-0.16897252 -1.1432782  -0.21855687]]\n",
      "[[-5.46518228e-01 -1.28811628e-04]] [[-0.17070991 -1.145094   -0.22269475]]\n",
      "[[-0.50493326  0.00199986]] [[-1.1408032  -0.23660575 -0.21099696]]\n",
      "[[-0.54068034  0.00303722]] [[-1.1442306  -0.24547954 -0.22074811]]\n",
      "[[-0.52343701  0.00250263]] [[-0.16788632 -1.1424516  -0.21604806]]\n",
      "[[-5.46389417e-01 -2.99608291e-04]] [[-0.17070055 -1.1451035  -0.2226773 ]]\n",
      "[[-0.53851507  0.00216528]] [[-0.16968304 -1.1439981  -0.22024338]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-1.1450955  -0.24714555 -0.22250643]]\n",
      "[[-5.46475279e-01  4.29488524e-05]] [[-0.17069888 -1.1450675  -0.22266464]]\n",
      "[[-0.54371756  0.00188642]] [[-0.17030859 -0.24638389 -1.1444228 ]]\n",
      "[[-5.45876668e-01  3.84222940e-04]] [[-1.1450934  -0.24710976 -0.22246325]]\n",
      "[[-5.04359734e-01 -2.86415473e-04]] [[-1.1410433  -0.23673882 -0.21108149]]\n",
      "[[-5.46325486e-01 -4.48817223e-04]] [[-0.17069817 -0.24732389 -1.1449864 ]]\n",
      "[[-0.51461785  0.00239345]] [[-0.16684604 -0.23899616 -1.141457  ]]\n",
      "[[-0.52593963  0.00348507]] [[-1.1427034  -0.24171405 -0.21663411]]\n",
      "[[-0.51461785  0.00239345]] [[-0.20144345 -0.27773336 -1.1707917 ]]\n",
      "[[-0.5170113   0.00144286]] [[-0.20182227 -0.27852657 -1.171227  ]]\n",
      "[[-0.50905792  0.00223382]] [[-0.2006516  -1.1702982  -0.23163386]]\n",
      "[[-0.54816503  0.        ]] [[-0.20634617 -0.2874977  -1.1752124 ]]\n",
      "[[-5.46089808e-01  5.31836926e-04]] [[-1.1751871  -0.28684616 -0.24262336]]\n",
      "[[-0.50693312  0.0021248 ]] [[-0.20035078 -1.1700581  -0.23102629]]\n",
      "[[-0.52343701  0.00250263]] [[-0.20270483 -1.1719941  -0.23579773]]\n",
      "[[-0.5294247   0.00344138]] [[-0.20352907 -1.1725733  -0.23743987]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-a4f2239e47b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[1;31m#run trials in memory through sampling to get next best move\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mdqn_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# internally iterates default (prediction) model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mdqn_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# iterates target model. updates the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f7f98ee8a4b4>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#predicts all 3 options in an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;31m#if we win/end then there are no more terminal states so we quit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\cform_75xk7s9\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32mC:\\Users\\cform_75xk7s9\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\cform_75xk7s9\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\cform_75xk7s9\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\cform_75xk7s9\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#our initial parameters\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "gamma   = 0.9\n",
    "epsilon = .95\n",
    "trials  = 1000\n",
    "trial_len = 500\n",
    "\n",
    "# updateTargetNetwork = 1000\n",
    "dqn_agent = DQN(env=env)\n",
    "steps = []\n",
    "for trial in range(trials):\n",
    "    #get a starting state\n",
    "    cur_state = env.reset().reshape(1,2)\n",
    "    for step in range(trial_len):\n",
    "        #make an action\n",
    "        action = dqn_agent.act(cur_state)\n",
    "        \n",
    "        #take next action\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        #reward = reward if not done else -20\n",
    "        new_state = new_state.reshape(1,2)\n",
    "        #add new state to memory\n",
    "        dqn_agent.remember(cur_state, action, reward, new_state, done)\n",
    "        \n",
    "        #run trials in memory through sampling to get next best move\n",
    "        dqn_agent.replay()       # internally iterates default (prediction) model\n",
    "        dqn_agent.target_train() # iterates target model. updates the weights\n",
    "\n",
    "        cur_state = new_state\n",
    "        if done:\n",
    "            break\n",
    "    if step >= 199:\n",
    "        print(\"Failed to complete in trial {}\".format(trial))\n",
    "        #if step % 10 == 0:\n",
    "        #    dqn_agent.save_model(\"trial-{}.model\".format(trial))\n",
    "    else:\n",
    "        print(\"Completed in {} trials\".format(trial))\n",
    "        #dqn_agent.save_model(\"success.model\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42457704,  0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset() #corresponds to your physical location and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n #corresponds to pushing left, right or not pushing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample() #corresponds to the action taken"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
